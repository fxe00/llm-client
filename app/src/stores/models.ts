import { defineStore } from 'pinia'
import { ref, computed } from 'vue'

// æ‰©å±•Windowæ¥å£ä»¥æ”¯æŒElectron API
declare global {
  interface Window {
    electronAPI?: {
      saveModels?: (models: any[]) => Promise<void>
      loadModels?: () => Promise<any[]>
      openStorageDirectory?: () => Promise<void>
      getStoragePath?: () => Promise<string>
      exportModels?: (filePath: string) => Promise<void>
      importModels?: (filePath: string) => Promise<any[]>
      saveSessions?: (sessions: any[]) => Promise<void>
      loadSessions?: () => Promise<any[]>
      exportSessions?: (sessions: any[]) => Promise<void>
      importSessions?: () => Promise<any[]>
      savePrompts?: (prompts: any[]) => Promise<void>
      loadPrompts?: () => Promise<any[]>
      exportPrompts?: (prompts: any[]) => Promise<void>
      importPrompts?: () => Promise<any[]>
    }
  }
}

export interface ModelConfig {
  id: string
  name: string
  provider: 'openai' | 'anthropic' | 'custom'
  apiEndpoint: string
  apiKey: string
  modelId: string
  maxTokens: number
  temperature: number
  systemPrompt?: string
  isDefault: boolean
  isEnabled: boolean
  description?: string
  capabilities: string[]
}

export interface ModelProvider {
  id: string
  name: string
  icon: string
  description: string
  supportedModels: string[]
  defaultEndpoint: string
}

export const useModelsStore = defineStore('models', () => {
  // é»˜è®¤æ¨¡å‹é…ç½®
  const defaultModels: ModelConfig[] = [
    {
      id: 'gpt-3.5-turbo',
      name: 'GPT-3.5 Turbo',
      provider: 'openai',
      apiEndpoint: 'https://api.openai.com/v1',
      apiKey: '',
      modelId: 'gpt-3.5-turbo',
      maxTokens: 4096,
      temperature: 0.8,
      systemPrompt: 'You are a helpful AI assistant.',
      isDefault: true,
      isEnabled: true,
      description: 'å¿«é€Ÿã€é«˜æ•ˆçš„å¯¹è¯æ¨¡å‹ï¼Œé€‚åˆæ—¥å¸¸ä½¿ç”¨',
      capabilities: ['chat', 'completion', 'code']
    },
    {
      id: 'gpt-4',
      name: 'GPT-4',
      provider: 'openai',
      apiEndpoint: 'https://api.openai.com/v1',
      apiKey: '',
      modelId: 'gpt-4',
      maxTokens: 8192,
      temperature: 0.7,
      systemPrompt: 'You are a helpful AI assistant with advanced reasoning capabilities.',
      isDefault: false,
      isEnabled: true,
      description: 'æœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰å¼ºå¤§çš„æ¨ç†èƒ½åŠ›',
      capabilities: ['chat', 'completion', 'code', 'reasoning', 'analysis']
    },
    {
      id: 'claude-3-sonnet',
      name: 'Claude 3 Sonnet',
      provider: 'anthropic',
      apiEndpoint: 'https://api.anthropic.com',
      apiKey: '',
      modelId: 'claude-3-sonnet-20240229',
      maxTokens: 4096,
      temperature: 0.7,
      systemPrompt: 'You are Claude, an AI assistant created by Anthropic.',
      isDefault: false,
      isEnabled: true,
      description: 'å¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡çš„æ¨¡å‹ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡',
      capabilities: ['chat', 'completion', 'analysis', 'writing']
    }
  ]

  // æ¨¡å‹æä¾›å•†
  const providers: ModelProvider[] = [
    {
      id: 'openai',
      name: 'OpenAI',
      icon: 'ğŸ¤–',
      description: 'OpenAIçš„GPTç³»åˆ—æ¨¡å‹',
      supportedModels: ['gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo'],
      defaultEndpoint: 'https://api.openai.com/v1'
    },
    {
      id: 'anthropic',
      name: 'Anthropic',
      icon: 'ğŸ§ ',
      description: 'Anthropicçš„Claudeç³»åˆ—æ¨¡å‹',
      supportedModels: ['claude-3-sonnet', 'claude-3-opus', 'claude-3-haiku'],
      defaultEndpoint: 'https://api.anthropic.com'
    },
    {
      id: 'custom',
      name: 'è‡ªå®šä¹‰',
      icon: 'âš™ï¸',
      description: 'è‡ªå®šä¹‰APIç«¯ç‚¹',
      supportedModels: [],
      defaultEndpoint: ''
    }
  ]

  // å“åº”å¼çŠ¶æ€
  const models = ref<ModelConfig[]>([])
  const selectedModelId = ref<string>('')
  const isTestingConnection = ref(false)
  const testResults = ref<{ [key: string]: { success: boolean; message: string; latency?: number } }>({})

  // è®¡ç®—å±æ€§
  const enabledModels = computed(() => models.value.filter(model => model.isEnabled))
  const defaultModel = computed(() => models.value.find(model => model.isDefault))
  const selectedModel = computed(() => models.value.find(model => model.id === selectedModelId.value))

  // æ–¹æ³•
  const loadModels = async () => {
    try {
      // ä¼˜å…ˆä»æ–‡ä»¶ç³»ç»ŸåŠ è½½
      if (window.electronAPI && window.electronAPI.loadModels) {
        try {
          const fileModels = await window.electronAPI.loadModels()
          if (fileModels && fileModels.length > 0) {
            models.value = fileModels
            console.log('âœ… æ¨¡å‹é…ç½®å·²ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½:', fileModels.length, 'ä¸ªæ¨¡å‹')
            // åŒæ­¥åˆ°localStorageä½œä¸ºå¤‡ä»½
            localStorage.setItem('llm-client-models', JSON.stringify(fileModels))
            return
          }
        } catch (fileError) {
          console.warn('âš ï¸ ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½å¤±è´¥ï¼Œå°è¯•ä»localStorageåŠ è½½:', fileError)
        }
      }
      
      // ä»localStorageåŠ è½½
      const saved = localStorage.getItem('llm-client-models')
      if (saved) {
        const parsedModels = JSON.parse(saved)
        models.value = parsedModels
        console.log('âœ… æ¨¡å‹é…ç½®å·²ä»æœ¬åœ°å­˜å‚¨åŠ è½½:', parsedModels.length, 'ä¸ªæ¨¡å‹')
      } else {
        models.value = [...defaultModels]
        saveModels()
        console.log('ğŸ“ ä½¿ç”¨é»˜è®¤æ¨¡å‹é…ç½®å¹¶ä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨')
      }
    } catch (error) {
      console.error('âŒ åŠ è½½æ¨¡å‹é…ç½®å¤±è´¥:', error)
      models.value = [...defaultModels]
    }
  }

  const saveModels = async () => {
    try {
      // ä¿å­˜åˆ°localStorage
      localStorage.setItem('llm-client-models', JSON.stringify(models.value))
      console.log('ğŸ’¾ æ¨¡å‹é…ç½®å·²ä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨:', models.value.length, 'ä¸ªæ¨¡å‹')
      
      // åŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
      if (window.electronAPI && window.electronAPI.saveModels) {
        try {
          await window.electronAPI.saveModels(models.value)
          console.log('ğŸ’¾ æ¨¡å‹é…ç½®å·²åŒæ­¥åˆ°æ–‡ä»¶ç³»ç»Ÿ')
        } catch (fileError) {
          console.warn('âš ï¸ ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿå¤±è´¥ï¼Œä½†localStorageå·²ä¿å­˜:', fileError)
        }
      }
    } catch (error) {
      console.error('âŒ ä¿å­˜æ¨¡å‹é…ç½®å¤±è´¥:', error)
    }
  }

  const addModel = (model: Omit<ModelConfig, 'id'>) => {
    const newModel: ModelConfig = {
      ...model,
      id: `model-${Date.now()}`
    }
    models.value.push(newModel)
    saveModels()
    return newModel
  }

  const updateModel = (id: string, updates: Partial<ModelConfig>) => {
    const index = models.value.findIndex(model => model.id === id)
    if (index !== -1) {
      models.value[index] = { ...models.value[index], ...updates }
      saveModels()
    }
  }

  const deleteModel = (id: string) => {
    const index = models.value.findIndex(model => model.id === id)
    if (index !== -1) {
      models.value.splice(index, 1)
      saveModels()
    }
  }

  const setDefaultModel = (id: string) => {
    models.value.forEach(model => {
      model.isDefault = model.id === id
    })
    saveModels()
  }

  const toggleModelEnabled = (id: string) => {
    const model = models.value.find(m => m.id === id)
    if (model) {
      model.isEnabled = !model.isEnabled
      saveModels()
    }
  }

  const testModelConnection = async (modelId: string) => {
    const model = models.value.find(m => m.id === modelId)
    if (!model) return

    isTestingConnection.value = true
    testResults.value[modelId] = { success: false, message: 'æµ‹è¯•ä¸­...' }

    try {
      const startTime = Date.now()
      
      // è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„APIæµ‹è¯•
      // ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªæµ‹è¯•
      await new Promise(resolve => setTimeout(resolve, 1000))
      
      const latency = Date.now() - startTime
      testResults.value[modelId] = {
        success: true,
        message: 'è¿æ¥æˆåŠŸ',
        latency
      }
    } catch (error) {
      testResults.value[modelId] = {
        success: false,
        message: `è¿æ¥å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
      }
    } finally {
      isTestingConnection.value = false
    }
  }

  const getProvider = (providerId: string) => {
    return providers.find(p => p.id === providerId)
  }

  const getAvailableProviders = () => {
    return providers
  }

  const getStorageInfo = async () => {
    const storageInfo = {
      type: 'localStorage',
      key: 'llm-client-models',
      location: 'æµè§ˆå™¨æœ¬åœ°å­˜å‚¨',
      filePath: '',
      modelsCount: models.value.length,
      lastSaved: new Date().toLocaleString()
    }
    
    // å¦‚æœæ˜¯Electronç¯å¢ƒï¼Œè·å–æ–‡ä»¶è·¯å¾„
    if (window.electronAPI && window.electronAPI.getStoragePath) {
      try {
        storageInfo.filePath = await window.electronAPI.getStoragePath()
        storageInfo.location = 'æ–‡ä»¶ç³»ç»Ÿå­˜å‚¨'
        storageInfo.type = 'file'
      } catch (error) {
        console.warn('è·å–å­˜å‚¨è·¯å¾„å¤±è´¥:', error)
      }
    }
    
    return storageInfo
  }

  const openStorageDirectory = async () => {
    if (window.electronAPI && window.electronAPI.openStorageDirectory) {
      try {
        await window.electronAPI.openStorageDirectory()
        console.log('ğŸ“ å·²æ‰“å¼€å­˜å‚¨ç›®å½•')
      } catch (error) {
        console.error('âŒ æ‰“å¼€å­˜å‚¨ç›®å½•å¤±è´¥:', error)
        alert('æ‰“å¼€å­˜å‚¨ç›®å½•å¤±è´¥: ' + error)
      }
    } else {
      alert('å½“å‰ç¯å¢ƒä¸æ”¯æŒæ‰“å¼€å­˜å‚¨ç›®å½•')
    }
  }

  const exportModels = async () => {
    if (window.electronAPI && window.electronAPI.exportModels) {
      try {
        // è®©ç”¨æˆ·é€‰æ‹©å¯¼å‡ºè·¯å¾„
        await window.electronAPI.exportModels('')
        console.log('ğŸ“¤ æ¨¡å‹é…ç½®å·²å¯¼å‡º')
        alert('æ¨¡å‹é…ç½®å·²å¯¼å‡º')
      } catch (error) {
        console.error('âŒ å¯¼å‡ºæ¨¡å‹é…ç½®å¤±è´¥:', error)
        alert('å¯¼å‡ºå¤±è´¥: ' + error)
      }
    } else {
      // æµè§ˆå™¨ç¯å¢ƒï¼Œä½¿ç”¨ä¸‹è½½
      const dataStr = JSON.stringify(models.value, null, 2)
      const dataBlob = new Blob([dataStr], { type: 'application/json' })
      const url = URL.createObjectURL(dataBlob)
      const link = document.createElement('a')
      link.href = url
      link.download = `llm-client-models-${new Date().toISOString().split('T')[0]}.json`
      link.click()
      URL.revokeObjectURL(url)
    }
  }

  const importModels = async () => {
    if (window.electronAPI && window.electronAPI.importModels) {
      try {
        const importedModels = await window.electronAPI.importModels('')
        if (importedModels && importedModels.length > 0) {
          models.value = importedModels
          await saveModels()
          console.log('ğŸ“¥ æ¨¡å‹é…ç½®å·²å¯¼å…¥:', importedModels.length, 'ä¸ªæ¨¡å‹')
          alert('æ¨¡å‹é…ç½®å·²å¯¼å…¥: ' + importedModels.length + 'ä¸ªæ¨¡å‹')
        }
      } catch (error) {
        console.error('âŒ å¯¼å…¥æ¨¡å‹é…ç½®å¤±è´¥:', error)
        alert('å¯¼å…¥å¤±è´¥: ' + error)
      }
    } else {
      // æµè§ˆå™¨ç¯å¢ƒï¼Œä½¿ç”¨æ–‡ä»¶é€‰æ‹©
      const input = document.createElement('input')
      input.type = 'file'
      input.accept = '.json'
      input.onchange = async (e) => {
        const target = e.target as HTMLInputElement
        if (target && target.files && target.files.length > 0) {
          const file = target.files[0]
          try {
            const text = await file.text()
            const importedModels = JSON.parse(text)
            models.value = importedModels
            await saveModels()
            console.log('ğŸ“¥ æ¨¡å‹é…ç½®å·²å¯¼å…¥:', importedModels.length, 'ä¸ªæ¨¡å‹')
            alert('æ¨¡å‹é…ç½®å·²å¯¼å…¥: ' + importedModels.length + 'ä¸ªæ¨¡å‹')
          } catch (error) {
            console.error('âŒ å¯¼å…¥æ¨¡å‹é…ç½®å¤±è´¥:', error)
            alert('å¯¼å…¥å¤±è´¥: ' + error)
          }
        }
      }
      input.click()
    }
  }

  // åˆå§‹åŒ–
  loadModels()

  return {
    // çŠ¶æ€
    models,
    selectedModelId,
    isTestingConnection,
    testResults,
    
    // è®¡ç®—å±æ€§
    enabledModels,
    defaultModel,
    selectedModel,
    
    // æ–¹æ³•
    addModel,
    updateModel,
    deleteModel,
    setDefaultModel,
    toggleModelEnabled,
    testModelConnection,
    getProvider,
    getAvailableProviders,
    getStorageInfo,
    openStorageDirectory,
    exportModels,
    importModels,
    loadModels,
    saveModels
  }
})
